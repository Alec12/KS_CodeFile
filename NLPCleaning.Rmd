---
title: "142 NLP Exploration"
author: "Lillian Dong"
date: "12/2/2018"
output: html_document
---
```{r}
library(tm)
library(SnowballC)
library(wordcloud)
library(MASS)
library(caTools)
library(dplyr)
library(rpart)
library(rpart.plot)
library(randomForest)
library(caret)
library(lubridate)

```

```{r}
library(readr)
#preliminary exploration with just one dataset. 
nlp_data <- read.csv("merged data 50000.csv", stringsAsFactors = FALSE)

#filter for US only
nlp_data = nlp_data %>% 
  filter(country == 'US')

#keep only successful and failed kickstarters
nlp_data = nlp_data %>% filter(state == 'successful' | state == 'failed')

nlp_data$Success = as.factor(as.numeric(nlp_data$state == 'successful'))
nlp_data$launched = as.Date(nlp_data$launched)
nlp_data <- nlp_data %>% mutate(deadline = ymd(deadline))
#nlp_data$category = as.factor(nlp_data$category) Dom: I commented this out since we're gonna end up with 150~ subcategories, tahts insaaaaneee
nlp_data$main_category = as.factor(nlp_data$main_category)
nlp_data$staff_pick = as.factor(as.numeric(nlp_data$staff_pick == 'True'))

table(nlp_data$Success)


#get blurb and names
only_name = nlp_data$name
only_blurb = nlp_data$blurb

# mostly not Successful (3150/(3150+1850))
corpusN = Corpus(VectorSource(only_name))
corpusB = Corpus(VectorSource(only_blurb))

corpusN = tm_map(corpusN, tolower)
corpusN = tm_map(corpusN, removePunctuation)
corpusB = tm_map(corpusB, tolower)
corpusB = tm_map(corpusB, removePunctuation)

corpusN = tm_map(corpusN, removeWords, stopwords("english"))
corpusN = tm_map(corpusN, stemDocument)
strwrap(corpusN[[1]])
corpusB = tm_map(corpusB, removeWords, stopwords("english"))
corpusB = tm_map(corpusB, stemDocument)
strwrap(corpusB[[1]])

frequenciesN = DocumentTermMatrix(corpusN)
frequenciesB = DocumentTermMatrix(corpusB)
frequenciesN
frequenciesB

findFreqTerms(frequenciesN,lowfreq = 50)
sparseN = removeSparseTerms(frequenciesN,0.99)
sparseN

findFreqTerms(frequenciesB, lowfreq=50)
sparseB = removeSparseTerms(frequenciesB, 0.98)
sparseB

# Step 8: Create data frame from the document-term matrix
nlpN = as.data.frame(as.matrix(sparseN))
nlpB = as.data.frame(as.matrix(sparseB))

# We have some variable names that start with a number, 
colnames(nlpN) = make.names(paste0("n.",colnames(nlpN)))
colnames(nlpB) = make.names(paste0("b.",colnames(nlpB)))

head(nlpN)
head(nlpB)

#Join
BlurbTM2 = cbind(nlpN,nlpB)

#append
BlurbTM2$Success = nlp_data$Success
BlurbTM2$launched = nlp_data$launched
#BlurbTM2$launched = NULL

#remove features not used for modeling
nlp_data$usd_pledged_real <- NULL
nlp_data$country <- NULL
nlp_data$usd.pledged <- NULL
nlp_data$usd_goal_real <- NULL
nlp_data$blurb <- NULL
nlp_data$name <- NULL
nlp_data$X <- NULL
nlp_data$currency <- NULL

write.csv(BlurbTM, file = 'blurbs_50000.csv')
```

